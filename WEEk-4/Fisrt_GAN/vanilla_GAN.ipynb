{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tH0Z2npYw21B"
   },
   "source": [
    "#Defining directories storing images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 842,
     "status": "ok",
     "timestamp": 1688496124803,
     "user": {
      "displayName": "Amit Malakar",
      "userId": "08866686481455390632"
     },
     "user_tz": -330
    },
    "id": "QSl2sJMbuM7S",
    "outputId": "4eebe1ba-01e7-4ce3-ddaf-edbf800af899"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘diff-run’: File exists\n"
     ]
    }
   ],
   "source": [
    "!mkdir diff-run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1688496125613,
     "user": {
      "displayName": "Amit Malakar",
      "userId": "08866686481455390632"
     },
     "user_tz": -330
    },
    "id": "LlUfVyFfucX-",
    "outputId": "5e23dd31-f711-4034-cddc-92519b8b722d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘diff-run/images’: File exists\n"
     ]
    }
   ],
   "source": [
    "!mkdir diff-run/images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "64US14lVw4RP"
   },
   "source": [
    "# Importing modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 4668,
     "status": "ok",
     "timestamp": 1688496130276,
     "user": {
      "displayName": "Amit Malakar",
      "userId": "08866686481455390632"
     },
     "user_tz": -330
    },
    "id": "--IOucB2ufHR"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "from torchvision.utils import save_image\n",
    "from torchvision.utils import make_grid\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1688496130276,
     "user": {
      "displayName": "Amit Malakar",
      "userId": "08866686481455390632"
     },
     "user_tz": -330
    },
    "id": "YoLi90E-umE_",
    "outputId": "c04b0080-b0be-40dd-fb8b-8b2de1e8a709"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f53944e9790>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1688496130277,
     "user": {
      "displayName": "Amit Malakar",
      "userId": "08866686481455390632"
     },
     "user_tz": -330
    },
    "id": "bLeRH9ZAumdR"
   },
   "outputs": [],
   "source": [
    "writer = SummaryWriter('diff-run/py-gan')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fCxbmgUixDdq"
   },
   "source": [
    "# Setting up device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1688496130277,
     "user": {
      "displayName": "Amit Malakar",
      "userId": "08866686481455390632"
     },
     "user_tz": -330
    },
    "id": "pmFk1busuo41"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1-ddvDSPxGYb"
   },
   "source": [
    "# Loading dataset and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1688496130277,
     "user": {
      "displayName": "Amit Malakar",
      "userId": "08866686481455390632"
     },
     "user_tz": -330
    },
    "id": "yhHB6ytMupSs"
   },
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5])])\n",
    "train_dataset = datasets.FashionMNIST(root='./data/', train=True, transform=train_transform, download=True)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1688496130278,
     "user": {
      "displayName": "Amit Malakar",
      "userId": "08866686481455390632"
     },
     "user_tz": -330
    },
    "id": "xkf4t8yqupoY"
   },
   "outputs": [],
   "source": [
    "image_shape = (1, 28, 28)\n",
    "image_dim = int(np.prod(image_shape))\n",
    "latent_dim = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cfVurPm1xNPb"
   },
   "source": [
    "# Building the Generator model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1688496130278,
     "user": {
      "displayName": "Amit Malakar",
      "userId": "08866686481455390632"
     },
     "user_tz": -330
    },
    "id": "aV8HYKc5up77"
   },
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        self.model = nn.Sequential(nn.Linear(latent_dim, 128),\n",
    "                                    nn.LeakyReLU(0.2, inplace=True),\n",
    "                                    nn.Linear(128, 256),\n",
    "                      nn.BatchNorm1d(256, 0.8),\n",
    "                                    nn.LeakyReLU(0.2, inplace=True),\n",
    "                                    nn.Linear(256, 512),\n",
    "                      nn.BatchNorm1d(512, 0.8),\n",
    "                                    nn.LeakyReLU(0.2, inplace=True),\n",
    "                      nn.Linear(512, 1024),\n",
    "                      nn.BatchNorm1d(1024, 0.8),\n",
    "                                    nn.LeakyReLU(0.2, inplace=True),\n",
    "                                    nn.Linear(1024, image_dim),\n",
    "                                    nn.Tanh())\n",
    "\n",
    "    def forward(self, noise_vector):\n",
    "        image = self.model(noise_vector)\n",
    "        image = image.view(image.size(0), *image_shape)\n",
    "        return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ysKPBOyuxR3Y"
   },
   "source": [
    "# Building the Discriminator model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1688496130278,
     "user": {
      "displayName": "Amit Malakar",
      "userId": "08866686481455390632"
     },
     "user_tz": -330
    },
    "id": "UkWPsmEcuqM_"
   },
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        self.model = nn.Sequential(nn.Linear(image_dim, 512),\n",
    "                                    nn.LeakyReLU(0.2, inplace=True),\n",
    "                                    nn.Linear(512, 256),\n",
    "                                    nn.LeakyReLU(0.2, inplace=True),\n",
    "                                    nn.Linear(256, 1),\n",
    "                                    nn.Sigmoid())\n",
    "\n",
    "    def forward(self, image):\n",
    "        image_flattened = image.view(image.size(0), -1)\n",
    "        result = self.model(image_flattened)\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1688496130279,
     "user": {
      "displayName": "Amit Malakar",
      "userId": "08866686481455390632"
     },
     "user_tz": -330
    },
    "id": "EwsWV8AHuqeR"
   },
   "outputs": [],
   "source": [
    "generator = Generator().to(device)\n",
    "discriminator = Discriminator().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1688496130280,
     "user": {
      "displayName": "Amit Malakar",
      "userId": "08866686481455390632"
     },
     "user_tz": -330
    },
    "id": "IAC-XRTNuqrm",
    "outputId": "6fdcaf4e-52e5-4633-90ed-11f258bf5a16"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1                  [-1, 128]          12,928\n",
      "         LeakyReLU-2                  [-1, 128]               0\n",
      "            Linear-3                  [-1, 256]          33,024\n",
      "       BatchNorm1d-4                  [-1, 256]             512\n",
      "         LeakyReLU-5                  [-1, 256]               0\n",
      "            Linear-6                  [-1, 512]         131,584\n",
      "       BatchNorm1d-7                  [-1, 512]           1,024\n",
      "         LeakyReLU-8                  [-1, 512]               0\n",
      "            Linear-9                 [-1, 1024]         525,312\n",
      "      BatchNorm1d-10                 [-1, 1024]           2,048\n",
      "        LeakyReLU-11                 [-1, 1024]               0\n",
      "           Linear-12                  [-1, 784]         803,600\n",
      "             Tanh-13                  [-1, 784]               0\n",
      "================================================================\n",
      "Total params: 1,510,032\n",
      "Trainable params: 1,510,032\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.05\n",
      "Params size (MB): 5.76\n",
      "Estimated Total Size (MB): 5.82\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(generator, (100,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1688496130281,
     "user": {
      "displayName": "Amit Malakar",
      "userId": "08866686481455390632"
     },
     "user_tz": -330
    },
    "id": "F5ZGa8p7uq4f",
    "outputId": "c27e7611-6a9a-4700-fcaa-876e1ccbe41a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1                  [-1, 512]         401,920\n",
      "         LeakyReLU-2                  [-1, 512]               0\n",
      "            Linear-3                  [-1, 256]         131,328\n",
      "         LeakyReLU-4                  [-1, 256]               0\n",
      "            Linear-5                    [-1, 1]             257\n",
      "           Sigmoid-6                    [-1, 1]               0\n",
      "================================================================\n",
      "Total params: 533,505\n",
      "Trainable params: 533,505\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.01\n",
      "Params size (MB): 2.04\n",
      "Estimated Total Size (MB): 2.05\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(discriminator, (1,28,28))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3IU8l0Z4xtV5"
   },
   "source": [
    "# Defining loss function (here binary cross entropy error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1688496130281,
     "user": {
      "displayName": "Amit Malakar",
      "userId": "08866686481455390632"
     },
     "user_tz": -330
    },
    "id": "gSM-rtCivScM"
   },
   "outputs": [],
   "source": [
    "adversarial_loss = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T-nqgjmUx2i4"
   },
   "source": [
    "# Optimization of Generator and Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1688496130281,
     "user": {
      "displayName": "Amit Malakar",
      "userId": "08866686481455390632"
     },
     "user_tz": -330
    },
    "id": "fpq5Zt8ZvSYu"
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.0002\n",
    "G_optimizer = optim.Adam(generator.parameters(), lr = learning_rate, betas=(0.5, 0.999))\n",
    "D_optimizer = optim.Adam(discriminator.parameters(), lr = learning_rate, betas=(0.5, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1688496130282,
     "user": {
      "displayName": "Amit Malakar",
      "userId": "08866686481455390632"
     },
     "user_tz": -330
    },
    "id": "M7vz5-k2vSWP"
   },
   "outputs": [],
   "source": [
    "cuda = True if torch.cuda.is_available() else False\n",
    "Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6pgYlqVNyCVj"
   },
   "source": [
    "#Training the GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1238068,
     "status": "ok",
     "timestamp": 1688499178505,
     "user": {
      "displayName": "Amit Malakar",
      "userId": "08866686481455390632"
     },
     "user_tz": -330
    },
    "id": "Fph9yPsdvST0",
    "outputId": "8e1afa70-f593-47dd-9320-03156298aee8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1/75]: D_loss: 1.019, G_loss: 1.369\n",
      "Epoch: [2/75]: D_loss: 0.886, G_loss: 2.059\n",
      "Epoch: [3/75]: D_loss: 0.883, G_loss: 1.989\n",
      "Epoch: [4/75]: D_loss: 1.021, G_loss: 1.658\n",
      "Epoch: [5/75]: D_loss: 1.100, G_loss: 1.415\n",
      "Epoch: [6/75]: D_loss: 1.130, G_loss: 1.396\n",
      "Epoch: [7/75]: D_loss: 1.126, G_loss: 1.347\n",
      "Epoch: [8/75]: D_loss: 1.150, G_loss: 1.279\n",
      "Epoch: [9/75]: D_loss: 1.158, G_loss: 1.279\n",
      "Epoch: [10/75]: D_loss: 1.199, G_loss: 1.173\n",
      "Epoch: [11/75]: D_loss: 1.210, G_loss: 1.142\n",
      "Epoch: [12/75]: D_loss: 1.231, G_loss: 1.113\n",
      "Epoch: [13/75]: D_loss: 1.229, G_loss: 1.087\n",
      "Epoch: [14/75]: D_loss: 1.226, G_loss: 1.110\n",
      "Epoch: [15/75]: D_loss: 1.234, G_loss: 1.092\n",
      "Epoch: [16/75]: D_loss: 1.248, G_loss: 1.071\n",
      "Epoch: [17/75]: D_loss: 1.243, G_loss: 1.045\n",
      "Epoch: [18/75]: D_loss: 1.254, G_loss: 1.038\n",
      "Epoch: [19/75]: D_loss: 1.247, G_loss: 1.028\n",
      "Epoch: [20/75]: D_loss: 1.244, G_loss: 1.041\n",
      "Epoch: [21/75]: D_loss: 1.247, G_loss: 1.026\n",
      "Epoch: [22/75]: D_loss: 1.242, G_loss: 1.027\n",
      "Epoch: [23/75]: D_loss: 1.251, G_loss: 1.016\n",
      "Epoch: [24/75]: D_loss: 1.249, G_loss: 1.020\n",
      "Epoch: [25/75]: D_loss: 1.258, G_loss: 0.996\n",
      "Epoch: [26/75]: D_loss: 1.265, G_loss: 0.992\n",
      "Epoch: [27/75]: D_loss: 1.265, G_loss: 0.975\n",
      "Epoch: [28/75]: D_loss: 1.255, G_loss: 1.007\n",
      "Epoch: [29/75]: D_loss: 1.256, G_loss: 0.991\n",
      "Epoch: [30/75]: D_loss: 1.256, G_loss: 0.982\n",
      "Epoch: [31/75]: D_loss: 1.257, G_loss: 0.984\n",
      "Epoch: [32/75]: D_loss: 1.264, G_loss: 0.965\n",
      "Epoch: [33/75]: D_loss: 1.258, G_loss: 0.969\n",
      "Epoch: [34/75]: D_loss: 1.262, G_loss: 0.968\n",
      "Epoch: [35/75]: D_loss: 1.264, G_loss: 0.972\n",
      "Epoch: [36/75]: D_loss: 1.259, G_loss: 0.968\n",
      "Epoch: [37/75]: D_loss: 1.261, G_loss: 0.966\n",
      "Epoch: [38/75]: D_loss: 1.256, G_loss: 0.961\n",
      "Epoch: [39/75]: D_loss: 1.253, G_loss: 0.980\n",
      "Epoch: [40/75]: D_loss: 1.253, G_loss: 0.973\n",
      "Epoch: [41/75]: D_loss: 1.257, G_loss: 0.964\n",
      "Epoch: [42/75]: D_loss: 1.261, G_loss: 0.951\n",
      "Epoch: [43/75]: D_loss: 1.263, G_loss: 0.954\n",
      "Epoch: [44/75]: D_loss: 1.263, G_loss: 0.952\n",
      "Epoch: [45/75]: D_loss: 1.268, G_loss: 0.953\n",
      "Epoch: [46/75]: D_loss: 1.272, G_loss: 0.933\n",
      "Epoch: [47/75]: D_loss: 1.266, G_loss: 0.959\n",
      "Epoch: [48/75]: D_loss: 1.273, G_loss: 0.946\n",
      "Epoch: [49/75]: D_loss: 1.270, G_loss: 0.946\n",
      "Epoch: [50/75]: D_loss: 1.268, G_loss: 0.956\n",
      "Epoch: [51/75]: D_loss: 1.269, G_loss: 0.946\n",
      "Epoch: [52/75]: D_loss: 1.268, G_loss: 0.948\n",
      "Epoch: [53/75]: D_loss: 1.262, G_loss: 0.955\n",
      "Epoch: [54/75]: D_loss: 1.265, G_loss: 0.940\n",
      "Epoch: [55/75]: D_loss: 1.263, G_loss: 0.954\n",
      "Epoch: [56/75]: D_loss: 1.260, G_loss: 0.954\n",
      "Epoch: [57/75]: D_loss: 1.260, G_loss: 0.951\n",
      "Epoch: [58/75]: D_loss: 1.255, G_loss: 0.966\n",
      "Epoch: [59/75]: D_loss: 1.255, G_loss: 0.967\n",
      "Epoch: [60/75]: D_loss: 1.251, G_loss: 0.969\n",
      "Epoch: [61/75]: D_loss: 1.257, G_loss: 0.960\n",
      "Epoch: [62/75]: D_loss: 1.253, G_loss: 0.964\n",
      "Epoch: [63/75]: D_loss: 1.251, G_loss: 0.960\n",
      "Epoch: [64/75]: D_loss: 1.252, G_loss: 0.966\n",
      "Epoch: [65/75]: D_loss: 1.253, G_loss: 0.966\n",
      "Epoch: [66/75]: D_loss: 1.247, G_loss: 0.976\n",
      "Epoch: [67/75]: D_loss: 1.248, G_loss: 0.970\n",
      "Epoch: [68/75]: D_loss: 1.250, G_loss: 0.970\n",
      "Epoch: [69/75]: D_loss: 1.249, G_loss: 0.967\n",
      "Epoch: [70/75]: D_loss: 1.251, G_loss: 0.969\n",
      "Epoch: [71/75]: D_loss: 1.242, G_loss: 0.984\n",
      "Epoch: [72/75]: D_loss: 1.243, G_loss: 0.978\n",
      "Epoch: [73/75]: D_loss: 1.247, G_loss: 0.969\n",
      "Epoch: [74/75]: D_loss: 1.247, G_loss: 0.975\n",
      "Epoch: [75/75]: D_loss: 1.247, G_loss: 0.978\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 75\n",
    "D_loss_plot, G_loss_plot = [], []\n",
    "for epoch in range(1, num_epochs+1):\n",
    "\n",
    "    D_loss_list, G_loss_list = [], []\n",
    "\n",
    "    for index, (real_images, _) in enumerate(train_loader):\n",
    "        D_optimizer.zero_grad()     #zero out the old gradients\n",
    "        real_images = real_images.to(device)\n",
    "        real_target = Variable(torch.ones(real_images.size(0), 1).to(device))\n",
    "        fake_target = Variable(torch.zeros(real_images.size(0), 1).to(device))\n",
    "\n",
    "        # Training Discriminator on Real Data\n",
    "        D_real_loss = adversarial_loss(discriminator(real_images), real_target)\n",
    "\n",
    "        # noise vector sampled from a normal distribution\n",
    "        noise_vector = Variable(torch.randn(real_images.size(0), latent_dim).to(device))\n",
    "        noise_vector = noise_vector.to(device)\n",
    "        generated_image = generator(noise_vector)\n",
    "\n",
    "        # Training Discriminator on Fake Data\n",
    "        D_fake_loss = adversarial_loss(discriminator(generated_image),\\\n",
    "                                     fake_target)\n",
    "\n",
    "        D_total_loss = D_real_loss + D_fake_loss\n",
    "        D_loss_list.append(D_total_loss)\n",
    "        D_total_loss.backward()\n",
    "        D_optimizer.step()\n",
    "\n",
    "        # Train Generator on Discriminator's output\n",
    "        G_optimizer.zero_grad()     #zero out the old gradients\n",
    "        generated_image = generator(noise_vector)\n",
    "        G_loss = adversarial_loss(discriminator(generated_image), real_target)\n",
    "        G_loss_list.append(G_loss)\n",
    "\n",
    "        G_loss.backward()\n",
    "        G_optimizer.step()\n",
    "        d = generated_image.data\n",
    "\n",
    "        writer.add_scalar('Discriminator Loss',\n",
    "                            D_total_loss,\n",
    "                            epoch * len(train_loader) + index)\n",
    "\n",
    "        writer.add_scalar('Generator Loss',\n",
    "                            G_loss,\n",
    "                            epoch * len(train_loader) + index)\n",
    "\n",
    "\n",
    "    print('Epoch: [%d/%d]: D_loss: %.3f, G_loss: %.3f' % (\n",
    "            (epoch), num_epochs, torch.mean(torch.FloatTensor(D_loss_list)),\\\n",
    "             torch.mean(torch.FloatTensor(G_loss_list))))\n",
    "\n",
    "    D_loss_plot.append(torch.mean(torch.FloatTensor(D_loss_list)))\n",
    "    G_loss_plot.append(torch.mean(torch.FloatTensor(G_loss_list)))\n",
    "    save_image(generated_image.data[:90], 'diff-run/images/Final_Sample_%d'%epoch + '.png', nrow=10, normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4Qw_MyIrNPJM"
   },
   "source": [
    "# Making directory to store GAN generated images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1688499178507,
     "user": {
      "displayName": "Amit Malakar",
      "userId": "08866686481455390632"
     },
     "user_tz": -330
    },
    "id": "x-DuD46-Eoyv"
   },
   "outputs": [],
   "source": [
    "!mkdir diff-run/GANimages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R84hBLBaNmcB"
   },
   "source": [
    "#Saving the GAN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1688499178507,
     "user": {
      "displayName": "Amit Malakar",
      "userId": "08866686481455390632"
     },
     "user_tz": -330
    },
    "id": "ftIEGk6GDf7I",
    "outputId": "d5aa82d9-c37c-41c4-8ee9-1526bfd86e58"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the trained GAN model\n",
    "torch.save(generator.state_dict(), 'generator_model.pth')\n",
    "generator.load_state_dict(torch.load('generator_model.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-KtF0qStNus6"
   },
   "source": [
    "# Creating samples from the trained GAN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1688499178508,
     "user": {
      "displayName": "Amit Malakar",
      "userId": "08866686481455390632"
     },
     "user_tz": -330
    },
    "id": "B2wVitlRDt1o"
   },
   "outputs": [],
   "source": [
    "num_samples = 128\n",
    "latent_dim = 100\n",
    "random_input = torch.randn(num_samples, latent_dim).to(device)\n",
    "\n",
    "# Generate samples from the generator\n",
    "generator.eval()  # Set the generator to evaluation mode\n",
    "generated_samples = generator(random_input)\n",
    "\n",
    "# Specify the custom save location\n",
    "save_location = 'diff-run/GANimages/Final_generated_samples.png'\n",
    "\n",
    "# Save the generated samples\n",
    "save_image(generated_samples, save_location, normalize=True)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOcdnEDm+Dddqnp1BuVwWPp",
   "provenance": [
    {
     "file_id": "1r-DAFaZgZ1emUiVhSVYU1XrP3zJyossZ",
     "timestamp": 1688500519721
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
